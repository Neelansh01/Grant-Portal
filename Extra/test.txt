vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
vit_model.classifier = nn.Linear(vit_model.classifier.in_features, 31)

# Fine Tuning Unfreezing layers
for param in vit_model.parameters():
    param.requires_grad = True

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
vit_model = vit_model.to(device)

cross_entropy = nn.CrossEntropyLoss()
adam_optimizer = optim.Adam(vit_model.parameters(), lr=0.0001, weight_decay=1e-4)

# Learning rate schedule_optimizer
schedule_optimizer = ReduceLROnPlateau(adam_optimizer, mode='min', factor=0.1, patience=3, verbose=True)

# Training Model
def train_vit_model(vit_model, training_data, validation_data, cross_entropy, adam_optimizer, schedule_optimizer, epoch_count=20):
    baseline_accuracy = 0.0
    early_stopping_patience = 5
    check_early_stopping = 0

    for epoch in range(epoch_count):
        vit_model.train()
        active_difference = 0.0
        for images, annotations in training_data:
            images = images.to(device)
            annotations = annotations.to(device)

            adam_optimizer.zero_grad()
            derived_image = vit_model(images).logits
            loss = cross_entropy(derived_image, annotations)
            loss.backward()

            # Gradient clipping
            nn.utils.clip_grad_norm_(vit_model.parameters(), max_norm=2.0)

            adam_optimizer.step()
            active_difference += loss.item() * images.size(0)

        epoch_difference = active_difference / len(training_data.dataset)
        check_validation_set, _, _, _ = evaluate_model(vit_model, validation_data)

        schedule_optimizer.step(epoch_difference)

        if check_validation_set > baseline_accuracy:
            baseline_accuracy = check_validation_set
            torch.save(vit_model.state_dict(), 'best_vit.pth')
            check_early_stopping = 0
        else:
            check_early_stopping += 1

        print(f'Epoch [{epoch+1}/{epoch_count}], Loss: {epoch_difference:.4f}, Val Accuracy: {check_validation_set:.4f}')

        if check_early_stopping >= early_stopping_patience:
            print("Early stopping triggered")
            break

# Evaluation Metrics
def evaluate_model(vit_model, data_loader):
    vit_model.eval()
    predictions = []
    all_annotations = []
    with torch.no_grad():
        for images, annotations in data_loader:
            images = images.to(device)
            annotations = annotations.to(device)
            derived_image = vit_model(images).logits
            _, preds = torch.max(derived_image, 1)
            predictions.extend(preds.cpu().numpy())
            all_annotations.extend(annotations.cpu().numpy())

    accuracy = accuracy_score(all_annotations, predictions)
    precision = precision_score(all_annotations, predictions, average='weighted', zero_division=0)
    recall = recall_score(all_annotations, predictions, average='weighted', zero_division=0)
    f1 = f1_score(all_annotations, predictions, average='weighted', zero_division=0)
    return accuracy, precision, recall, f1

# Train the Model
train_vit_model(vit_model, training_data, validation_data, cross_entropy, adam_optimizer, schedule_optimizer, epoch_count=20)

# Load the model
vit_model.load_state_dict(torch.load('best_vit.pth'))

## Testing the Model
test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(vit_model, testing_data)
print(f'Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}')